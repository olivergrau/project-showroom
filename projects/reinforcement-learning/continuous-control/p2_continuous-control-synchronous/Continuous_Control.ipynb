{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# Monkey patch missing attributes for newer numpy versions\n",
    "if not hasattr(np, \"float_\"):\n",
    "    np.float_ = np.float64\n",
    "    \n",
    "if not hasattr(np, \"int_\"):\n",
    "    np.int_ = np.int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found path: /home/oliver/project-showroom/projects/reinforcement-learning/continuous-control/p2_continuous-control-synchronous/Reacher_Linux/Reacher.x86_64\n",
      "Mono path[0] = '/home/oliver/project-showroom/projects/reinforcement-learning/continuous-control/p2_continuous-control-synchronous/Reacher_Linux/Reacher_Data/Managed'\n",
      "Mono config path = '/home/oliver/project-showroom/projects/reinforcement-learning/continuous-control/p2_continuous-control-synchronous/Reacher_Linux/Reacher_Data/MonoBleedingEdge/etc'\n",
      "Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "Unable to preload the following plugins:\n",
      "\tScreenSelector.so\n",
      "\tlibgrpc_csharp_ext.x86.so\n",
      "\tScreenSelector.so\n",
      "Logging to /home/oliver/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Linux/Reacher.x86_64', no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "(20, 33)\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "print(states.shape)\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_moving_observation_slice(env, brain_name, num_agents=20, action_size=4, steps=100):\n",
    "    print(\"🔍 Running motion scan...\")\n",
    "    obs_log = []\n",
    "\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations\n",
    "\n",
    "    for i in range(steps):\n",
    "        actions = np.random.uniform(-1, 1, (num_agents, action_size))\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        state = env_info.vector_observations\n",
    "        obs_log.append(state[0])  # only track agent 0\n",
    "\n",
    "    obs_array = np.array(obs_log)  # shape: (steps, obs_dim)\n",
    "\n",
    "    # Compute std per dimension\n",
    "    std_per_dim = np.std(obs_array, axis=0)\n",
    "    print(f\"📐 Observation vector dim = {obs_array.shape[1]}\")\n",
    "    \n",
    "    # Look for most moving 3D slices\n",
    "    for i in range(0, len(std_per_dim) - 2):\n",
    "        slice_std = np.sum(std_per_dim[i:i+3])\n",
    "        if slice_std > 1e-3:  # filter out noise\n",
    "            print(f\"Candidate slice [{i}:{i+3}] has std sum {slice_std:.4f} → stds = {std_per_dim[i:i+3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Running motion scan...\n",
      "Step 1/50\n",
      "Step 2/50\n",
      "Step 3/50\n",
      "Step 4/50\n",
      "Step 5/50\n",
      "Step 6/50\n",
      "Step 7/50\n",
      "Step 8/50\n",
      "Step 9/50\n",
      "Step 10/50\n",
      "Step 11/50\n",
      "Step 12/50\n",
      "Step 13/50\n",
      "Step 14/50\n",
      "Step 15/50\n",
      "Step 16/50\n",
      "Step 17/50\n",
      "Step 18/50\n",
      "Step 19/50\n",
      "Step 20/50\n",
      "Step 21/50\n",
      "Step 22/50\n",
      "Step 23/50\n",
      "Step 24/50\n",
      "Step 25/50\n",
      "Step 26/50\n",
      "Step 27/50\n",
      "Step 28/50\n",
      "Step 29/50\n",
      "Step 30/50\n",
      "Step 31/50\n",
      "Step 32/50\n",
      "Step 33/50\n",
      "Step 34/50\n",
      "Step 35/50\n",
      "Step 36/50\n",
      "Step 37/50\n",
      "Step 38/50\n",
      "Step 39/50\n",
      "Step 40/50\n",
      "Step 41/50\n",
      "Step 42/50\n",
      "Step 43/50\n",
      "Step 44/50\n",
      "Step 45/50\n",
      "Step 46/50\n",
      "Step 47/50\n",
      "Step 48/50\n",
      "Step 49/50\n",
      "Step 50/50\n",
      "📐 Observation vector dim = 33\n",
      "Candidate slice [0:3] has std sum 2.3164 → stds = [1.31692796 0.1575788  0.84184435]\n",
      "Candidate slice [1:4] has std sum 1.0095 → stds = [0.1575788  0.84184435 0.01011591]\n",
      "Candidate slice [2:5] has std sum 1.0188 → stds = [0.84184435 0.01011591 0.16685545]\n",
      "Candidate slice [3:6] has std sum 0.1938 → stds = [0.01011591 0.16685545 0.01682419]\n",
      "Candidate slice [4:7] has std sum 0.2943 → stds = [0.16685545 0.01682419 0.11059877]\n",
      "Candidate slice [5:8] has std sum 0.6467 → stds = [0.01682419 0.11059877 0.51930308]\n",
      "Candidate slice [6:9] has std sum 0.7626 → stds = [0.11059877 0.51930308 0.13268047]\n",
      "Candidate slice [7:10] has std sum 1.1338 → stds = [0.51930308 0.13268047 0.48185172]\n",
      "Candidate slice [8:11] has std sum 2.5555 → stds = [0.13268047 0.48185172 1.94100747]\n",
      "Candidate slice [9:12] has std sum 2.9853 → stds = [0.48185172 1.94100747 0.5624041 ]\n",
      "Candidate slice [10:13] has std sum 4.4293 → stds = [1.94100747 0.5624041  1.92586649]\n",
      "Candidate slice [11:14] has std sum 3.8007 → stds = [0.5624041  1.92586649 1.31243896]\n",
      "Candidate slice [12:15] has std sum 4.0888 → stds = [1.92586649 1.31243896 0.85048748]\n",
      "Candidate slice [13:16] has std sum 3.1657 → stds = [1.31243896 0.85048748 1.00278083]\n",
      "Candidate slice [14:17] has std sum 1.9475 → stds = [0.85048748 1.00278083 0.09421135]\n",
      "Candidate slice [15:18] has std sum 1.2311 → stds = [1.00278083 0.09421135 0.13409038]\n",
      "Candidate slice [16:19] has std sum 0.3829 → stds = [0.09421135 0.13409038 0.154571  ]\n",
      "Candidate slice [17:20] has std sum 0.5920 → stds = [0.13409038 0.154571   0.30332258]\n",
      "Candidate slice [18:21] has std sum 2.1905 → stds = [0.154571   0.30332258 1.73264159]\n",
      "Candidate slice [19:22] has std sum 3.0215 → stds = [0.30332258 1.73264159 0.98553292]\n",
      "Candidate slice [20:23] has std sum 3.3550 → stds = [1.73264159 0.98553292 0.63679574]\n",
      "Candidate slice [21:24] has std sum 3.4762 → stds = [0.98553292 0.63679574 1.85385282]\n",
      "Candidate slice [22:25] has std sum 5.8154 → stds = [0.63679574 1.85385282 3.32479323]\n",
      "Candidate slice [23:26] has std sum 8.0211 → stds = [1.85385282 3.32479323 2.84245113]\n",
      "Candidate slice [24:27] has std sum 6.3303 → stds = [3.32479323 2.84245113 0.16309646]\n",
      "Candidate slice [25:28] has std sum 3.0055 → stds = [2.84245113 0.16309646 0.        ]\n",
      "Candidate slice [26:29] has std sum 0.4344 → stds = [0.16309646 0.         0.27126094]\n",
      "Candidate slice [27:30] has std sum 0.2713 → stds = [0.         0.27126094 0.        ]\n",
      "Candidate slice [28:31] has std sum 0.2713 → stds = [0.27126094 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#env = UnityEnvironment(file_name=\"Reacher_Linux/Reacher.x86_64\", no_graphics=True)\n",
    "brain_name = env.brain_names[0]\n",
    "find_moving_observation_slice(env, brain_name, steps=50)\n",
    "#env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.85377502e-02 -3.64059973e+00 -1.66121674e+00  9.77393091e-01\n",
      "  3.46945366e-03  7.50132371e-04 -2.11400598e-01  9.30635482e-02\n",
      " -1.49353864e-02  3.30568328e-02  1.45819858e-01  1.54888093e-01\n",
      " -3.40541005e-01 -1.32419968e+00 -7.77705240e+00 -6.31999969e-01\n",
      "  8.48606527e-01 -2.04001009e-01  1.17901683e-01  4.73655820e-01\n",
      " -1.14352691e+00 -7.18460500e-01 -4.20570135e-01 -3.06774259e+00\n",
      "  4.92994165e+00  4.79087770e-01  6.93596649e+00 -1.00000000e+00\n",
      "  3.98652649e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 20: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.06256866e-01 -3.66967893e+00 -1.58326721e+00  9.79209483e-01\n",
      "  2.51365490e-02  5.16924635e-03 -2.01221868e-01 -6.27368391e-01\n",
      " -2.63733286e-02  5.93717918e-02  2.60860652e-01 -1.01066196e+00\n",
      "  2.30751181e+00 -1.94613647e+00 -6.69010878e+00 -8.62930298e-01\n",
      "  6.72415912e-01 -2.97619790e-01  3.04072350e-01  6.05656147e-01\n",
      " -1.17306888e+00 -9.70679104e-01 -5.07012270e-02 -2.36291289e+00\n",
      "  1.78342426e+00  1.30767345e+00  5.05870438e+00 -1.00000000e+00\n",
      "  6.19754028e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 30: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 9.10999298e-01 -3.88965082e+00  2.35282898e-01  9.93028104e-01\n",
      "  1.13992795e-01 -3.35230771e-03  2.98277736e-02 -1.11505735e+00\n",
      "  2.47694086e-02  6.54563546e-01  2.57300687e+00  7.29294360e-01\n",
      "  4.35555315e+00 -1.34104156e+00 -6.37725115e+00  8.92524719e-01\n",
      "  1.68157354e-01 -7.22594112e-02  6.33191943e-01  7.52043664e-01\n",
      " -3.67014027e+00 -9.33292806e-01  1.54138827e+00  2.61044598e+00\n",
      " -2.27033043e+00  9.75716650e-01  2.51648331e+00 -1.00000000e+00\n",
      "  7.59390259e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 40: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.64210129e+00 -3.65020275e+00 -3.17993164e-02  9.77939188e-01\n",
      "  2.08845004e-01  9.13729542e-04 -4.24075546e-03  1.19270754e+00\n",
      " -8.82815337e-04 -5.92411757e-02 -2.17328280e-01 -1.62729666e-01\n",
      " -4.37306499e+00 -1.07391357e-01 -6.65733719e+00  2.38616943e-01\n",
      "  1.37046576e-01 -5.95867708e-02  7.25884616e-01  6.71386063e-01\n",
      "  5.19577742e+00  1.75511003e+00 -2.10798010e-01  1.05040587e-01\n",
      " -1.02858400e+00 -1.86531031e+00 -3.56533051e-01 -1.00000000e+00\n",
      "  7.99205017e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 50: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.09142303 -3.74211621 -0.90353012  0.98369431  0.13609089  0.01611549\n",
      " -0.11646949  0.34106198  0.01621385 -0.06953056 -0.27612522  0.22331062\n",
      " -1.30237877 -1.06800842 -6.95422125 -1.55290222  0.26989514 -0.23078442\n",
      "  0.70339322  0.61573792  4.56132936  0.85450214  0.50506246 -0.19263899\n",
      " -1.90261948 -1.03378332 -3.18268204 -1.          7.33965302  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 60: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.28030396 -3.67465544 -0.93325424  0.97935396  0.16012256  0.01991221\n",
      " -0.12177882 -0.17329127 -0.02168042  0.08460716  0.333038   -0.05628849\n",
      "  0.66769999 -0.58219147 -7.45405245 -1.59916306  0.66791904 -0.46504205\n",
      "  0.47337654  0.33694911 -4.23537111 -1.27326524 -0.22775626  0.20108169\n",
      "  0.93955249  2.36402035 -5.59046555 -1.          5.72247314  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 70: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.62110138 -3.55989265 -0.85631943  0.97182828 -0.20451812 -0.02414133\n",
      " -0.11462681 -0.06446269  0.38177696 -1.58005774 -6.06472921  2.31856036\n",
      "  0.8076424  -2.67631912 -9.19095039 -0.98129272  0.99203396  0.0181071\n",
      " -0.08900185  0.08728965 -0.62621099  1.52909958  2.72781467  2.52161026\n",
      "  4.41534472  4.21348381 -7.26338959 -1.          3.35308075  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 80: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.72336960e+00 -2.93712473e+00  6.25038147e-02  9.31496620e-01\n",
      " -3.63597125e-01  3.82575509e-03  9.82926693e-03 -1.16462862e+00\n",
      "  2.23789335e-04 -9.67214704e-02 -2.86535144e-01  2.55103290e-01\n",
      "  3.45077538e+00 -2.17846680e+00 -6.55773449e+00  7.12028503e-01\n",
      "  3.16948295e-01  7.66320601e-02 -7.97388673e-01  5.07782102e-01\n",
      " -4.56231165e+00  3.51677823e+00 -4.11130071e-01  1.99703538e+00\n",
      "  3.28626466e+00  2.58405447e+00 -7.98155594e+00 -1.00000000e+00\n",
      "  5.42915344e-01  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 90: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.98377228 -3.04568267  1.68231201  0.9366051  -0.24716771  0.06340139\n",
      "  0.24012373 -0.55317211  0.26336551  0.492778    1.94128323 -0.09102522\n",
      "  2.22785258 -0.98760986 -6.86111498  3.66860199  0.08236397 -0.09396205\n",
      " -0.86458558  0.48670235  5.9214077  -3.16505456  1.19311202  2.51681089\n",
      " -2.34650469  2.42223334 -7.65054703 -1.         -2.33861542  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 100: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.77878952 -3.13881946  2.36145401  0.94442332  0.09235311 -0.0307108\n",
      "  0.31399438  0.22924642  0.14837539  0.1965197   0.97209096 -0.39593408\n",
      " -0.83503842 -0.13566971 -8.08840466  4.35066223 -0.05213204 -0.02526589\n",
      " -0.96390116 -0.25988162  0.62541556  0.18250179 -1.20576739 -2.93212295\n",
      "  1.64027989 -3.50657344 -6.31387329 -1.         -4.9127388   0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 110: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.97211075 -3.69608474  1.18619919  0.98073113 -0.12036229  0.01875156\n",
      "  0.15273437  0.1962795  -0.10354253 -0.31983092 -1.31347799  0.06645893\n",
      " -0.82759392 -1.48315811 -9.46259022  1.97786713  0.04283478  0.01703736\n",
      " -0.99831921  0.03512558  1.33083749 -0.39854249  1.02505922  2.27797985\n",
      "  0.38015124 -7.27788353 -4.14723969 -1.         -6.84107971  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 120: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-5.78258514e-01 -3.85145521e+00 -9.22748566e-01  9.90579307e-01\n",
      " -7.16188997e-02 -8.40393174e-03 -1.16416313e-01  1.45417857e+00\n",
      "  1.81184355e-02 -8.72660503e-02 -3.54778230e-01  1.22658038e+00\n",
      " -5.65726423e+00 -1.50224304e+00 -8.90730381e+00 -3.62757111e+00\n",
      "  2.62786448e-03  3.61838490e-01 -9.27935183e-01 -8.94553959e-02\n",
      " -6.06380463e-01  2.20289007e-01  6.49953112e-02 -1.08185601e+00\n",
      "  2.53061712e-01 -7.79086781e+00 -1.43545151e+00 -1.00000000e+00\n",
      " -7.87016296e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 130: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.61162186 -2.16039729 -3.32148743  0.87742788 -0.06713904 -0.03623881\n",
      " -0.47360271  0.12728798  0.01903495 -0.01256508 -0.09062809  0.42977139\n",
      " -0.26702514 -1.8551712  -6.66728067 -5.50400925 -0.06151376 -0.04153804\n",
      " -0.9880119  -0.13536282 -0.08988571  0.03079662 -0.07326051 -0.45841467\n",
      "  0.87445718 -0.04591749  1.46502686 -1.         -7.86471176  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 140: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-9.41116333e-01 -3.05717659e+00 -2.41003036e+00  9.38733280e-01\n",
      " -1.11419030e-01 -3.84608768e-02 -3.23861659e-01 -4.23682392e-01\n",
      "  2.92346269e-01 -3.66736084e-01 -1.83724546e+00 -7.02890813e-01\n",
      "  1.56221628e+00 -2.78586197e+00 -8.09823799e+00 -4.61416245e+00\n",
      " -7.16407225e-02  8.31486657e-02 -9.75825787e-01 -1.88991904e-01\n",
      "  3.63077410e-02  5.92436874e-03  7.45120108e-01 -1.93925366e-01\n",
      " -2.51472116e+00  2.59129405e+00  4.17292404e+00 -1.00000000e+00\n",
      " -6.82544327e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 150: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-4.84043121e-01 -3.89508462e+00  7.86048889e-01  9.93283331e-01\n",
      " -5.99880591e-02  6.11771643e-03  9.87538993e-02 -1.23254287e+00\n",
      "  2.23152637e-01  1.26569295e+00  5.11486912e+00  1.08641312e-01\n",
      "  4.96174908e+00 -1.32684326e+00 -8.81250477e+00 -8.21800232e-01\n",
      "  1.54801849e-02  3.98442119e-01 -9.12138581e-01 -9.49082077e-02\n",
      "  1.99625361e+00  1.61643374e+00 -4.96507883e-01  2.28534341e+00\n",
      "  6.78571033e+00  3.42387938e+00  6.33229446e+00 -1.00000000e+00\n",
      " -4.88896942e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 160: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.96160507 -2.38545251  2.55511093  0.88835591  0.23145467 -0.0999594\n",
      "  0.38374567 -0.51360852  0.28823262  0.2769753   1.40898323  1.84099865\n",
      "  0.69692045  1.38742447 -5.36582756  2.60484314 -0.40153006  0.52030367\n",
      " -0.73226649 -0.17844771 -1.10718048  0.25307354  0.46268612  2.52187228\n",
      " -1.29747605  3.83218527  7.65928268 -1.         -2.30984497  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 170: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.46660995 -3.10140657  2.06738281  0.94089097  0.17776558 -0.05348186\n",
      "  0.28330767  1.10463774 -0.21069789 -0.30331054 -1.3785429  -2.80597806\n",
      " -3.07136512  1.30328751 -8.09188747  3.02440643 -0.18760099  0.14019416\n",
      " -0.95293349 -0.19253391 -1.5593189  -1.05116642  0.23360746 -0.49175534\n",
      " -6.83023357 -1.26620245  7.97945786 -1.          0.57291031  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 180: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.16690826 -3.69002652 -1.01915741  0.98030746 -0.14540289 -0.01957136\n",
      " -0.13218302  0.55528742  0.15924697 -0.6055243  -2.41783595  1.22302556\n",
      " -1.8955977   0.21521378 -7.47734737 -0.07696533 -0.37622488 -0.51808351\n",
      " -0.72683614  0.24850272 -2.83112884  1.3748827  -0.28698489 -1.21849191\n",
      "  8.34468269 -3.193156    7.25073624 -1.          3.38036346  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 190: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.18392181e+00 -3.25017190e+00 -2.01644897e+00  9.51351285e-01\n",
      " -1.43267035e-01 -4.06198427e-02 -2.69731939e-01  4.77815121e-01\n",
      " -7.15765520e-04  1.18437188e-03  5.31647215e-03  9.47099209e-01\n",
      " -1.57252824e+00  9.37309265e-02 -4.13745975e+00 -2.13676453e+00\n",
      " -3.75924110e-01 -8.63863528e-01 -3.15952510e-01  1.12226933e-01\n",
      "  1.42596632e-01  7.99111202e-02  6.38832226e-02  2.60016881e-02\n",
      "  1.56589520e+00 -2.67327833e+00  5.56890106e+00 -1.00000000e+00\n",
      "  5.74346161e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 200: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.33215332 -2.68553662 -2.9552269   0.91444016 -0.03785111 -0.01663761\n",
      " -0.40260378 -0.49914217 -0.36451331  0.3269932   1.96031249 -1.60888004\n",
      "  1.19885194  1.38276672 -6.40096664 -3.65081406 -0.171904   -0.35059538\n",
      " -0.86768156  0.30766961  2.18919992 -0.44134152  0.22151127  2.93629885\n",
      " -7.24641514 -1.93590868  3.15503693 -1.          7.35158539  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 210: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.84228134 -3.84067988  0.74717712  0.98990119  0.10485639 -0.0099542\n",
      "  0.09487814 -1.1091466   0.15313882  0.89238924  3.57373667  1.42925417\n",
      "  4.19651461  1.46756744 -9.25331593 -0.32212448 -0.06973901  0.28061134\n",
      " -0.9570809   0.01974463  1.20078671  2.3866272  -2.04938936 -7.09265709\n",
      "  4.74420166  2.13405061  0.32644272 -1.          7.99333954  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 220: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.87514496 -3.6353364   1.42664719  0.97683078  0.10761341 -0.0202715\n",
      "  0.1838751  -0.54134488 -0.09659332 -0.25569886 -1.07128251  0.52068996\n",
      "  2.07133579 -1.32265854 -7.26636457  2.26522446 -0.36770767  0.31020984\n",
      " -0.71769142 -0.50346792  2.81190777  0.31055105 -0.3192293  -2.40844655\n",
      "  3.05015945  1.03378129 -2.54506683 -1.          7.58436584  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 230: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.2063446  -3.10548043  1.24512863  0.94098753 -0.28101957  0.05410637\n",
      "  0.18067396  0.66019231 -0.74683499 -1.79614151 -6.70489979  2.85398149\n",
      " -3.65114665 -4.93084717 -8.23068523  2.50008774  0.0821223  -0.07019368\n",
      " -0.97823286 -0.17717031 -0.60698992  0.44780681  3.49074006  2.54329848\n",
      " -1.35359299 -3.08334517 -5.08201981 -1.          6.17843628  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 240: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.77154541 -2.85087132 -0.48807907  0.92524844 -0.3699207  -0.03122696\n",
      " -0.07809573  0.06114541 -0.06937137  0.41207951  1.20700371 -1.12293339\n",
      " -0.36813807 -2.5418396  -6.91634703 -0.99221039 -0.83676118 -0.37987617\n",
      " -0.34758031  0.18631358 -4.71845198  4.82587385  0.91102308  3.97263646\n",
      "  0.36783201 -3.24228621 -6.95094681 -1.          3.96034241  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 250: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.02548599 -3.70779133 -1.10868454  0.98134959 -0.12722261 -0.01866262\n",
      " -0.14289555  1.156057   -0.29507461  1.08387804  4.34053278 -0.03542622\n",
      " -4.63922834  0.40882492 -8.51003075 -2.28001404 -0.91370702 -0.40240666\n",
      "  0.01578527  0.05439837 -4.95181799  1.78603005 -1.17505205  3.0253334\n",
      " -7.34891558  0.01421691 -7.90616989 -1.          1.22166824  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 260: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.58084869 -3.49944973  1.12921143  0.96787095  0.19829226 -0.0310351\n",
      "  0.15146923 -0.18202873 -0.0459904  -0.14510231 -0.56187153 -0.02807239\n",
      "  0.71375751  1.37306595 -8.7261734   1.39909744 -0.95157671  0.21911955\n",
      "  0.16536374  0.13835935 -2.14872098 -0.55981421 -0.45409951 -2.16737103\n",
      " -1.25734794  8.34879589 -7.8221283  -1.         -1.67759705  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 270: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.67324448 -2.92698789  2.16439819  0.92845231 -0.2024103   0.06633519\n",
      "  0.30431247 -1.28640509 -0.04279727 -0.06150224 -0.27410462  2.79080009\n",
      "  3.79125929 -1.39431    -7.71206331  3.78024292 -0.9468171  -0.25931147\n",
      " -0.18370433  0.05047414  2.65634847 -1.06615198 -0.8102141  -3.7141633\n",
      "  2.57791829 -0.96901935 -6.70986176 -1.         -4.35634613  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 280: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.28061676 -3.43650746  1.60760498  0.96359706 -0.15753962  0.03494655\n",
      "  0.21316853  1.02860081 -0.38685486 -0.78774333 -3.36461592 -0.78177905\n",
      " -4.00944233 -2.94787216 -8.92202663  3.06124878 -0.99013728  0.11669209\n",
      " -0.05950794 -0.04969965 -0.95839137  0.33525747  1.38211596  0.15068467\n",
      " -2.7191875  -2.49390626 -4.71559143 -1.         -6.46244431  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 290: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.08570862e+00 -3.85027313e+00 -1.33148193e-01  9.90522683e-01\n",
      " -1.36260465e-01 -2.47283047e-03 -1.70846991e-02  1.16033661e+00\n",
      " -1.17391972e-02  1.03631771e+00  3.98868275e+00 -1.15885329e+00\n",
      " -4.47914600e+00 -2.18074799e-01 -9.13202667e+00 -9.11624908e-01\n",
      " -9.44374025e-01 -2.83502996e-01 -8.30332786e-02  1.44531325e-01\n",
      " -1.77258921e+00  1.39209521e+00 -2.15507403e-01  4.73001528e+00\n",
      " -4.45311785e+00 -5.14124823e+00 -2.10145187e+00 -1.00000000e+00\n",
      " -7.71905899e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 300: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.85635757 -2.46073794 -1.35980606  0.89408928  0.37288743  0.09551398\n",
      " -0.22899006 -0.61597848 -0.09341349  0.16529873  0.53888351 -0.38941896\n",
      "  1.78805733  2.27677155 -4.8920517  -3.53375244 -0.7601552   0.61878943\n",
      " -0.13842563  0.1417819  -1.95700705 -1.78586233 -2.75108218  1.01461577\n",
      "  7.24082708 -2.06621552  0.78892136 -1.         -7.96100616  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 310: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.11356735 -2.93436599 -1.72213364  0.92863595  0.26382455  0.07128164\n",
      " -0.25089991  0.40430635  0.01356286 -0.02371047 -0.09337784  0.63607961\n",
      " -1.22841036  3.17460632 -2.77061892 -4.77549362 -0.15793386  0.92220676\n",
      " -0.28348386  0.21030602 -0.03292449 -0.50630701 -0.52214491  2.99394441\n",
      "  1.45790839 -2.68078995  3.57559586 -1.         -7.15647507  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 320: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.32658005 -2.42687154 -2.90065002  0.89406824  0.15176795  0.07053308\n",
      " -0.41549212  0.17494701  0.12983721 -0.11032379 -0.64580601  0.35757026\n",
      " -0.60327786  4.32577896 -3.91177845 -7.26773453  0.18310983  0.66833496\n",
      " -0.64001352  0.33193663 -0.7961387  -0.24554785 -0.37711406 -0.10403304\n",
      " -3.10121179 -0.78882766  5.89225006 -1.         -5.41122818  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 330: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.69928741 -3.39348888 -2.00505066  0.9612636   0.08424678  0.02291868\n",
      " -0.26143762  0.19320013  0.14097768 -0.24227926 -1.10860014  0.20961809\n",
      " -0.7620551   2.96728134 -6.56407356 -5.86417389  0.13343665  0.56288856\n",
      " -0.76543254  0.28189403 -2.01725912 -0.32258639 -0.41153958 -1.10123014\n",
      " -7.86880064  1.03284991  7.43437195 -1.         -2.95467377  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 340: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-3.77758026e-01 -3.97911024e+00  2.19532013e-01  9.98518586e-01\n",
      " -4.70151529e-02  1.17373839e-03  2.73670275e-02 -1.80814254e+00\n",
      " -1.22232689e-02 -6.48579121e-01 -2.60089469e+00  3.48783106e-01\n",
      "  7.24433708e+00  1.06534958e+00 -8.57896519e+00 -1.46657944e+00\n",
      "  1.65568322e-01  4.06949729e-01 -8.61144722e-01  2.55751580e-01\n",
      "  1.91684854e+00 -2.83432543e-01 -6.70839131e-01 -5.43756247e+00\n",
      "  3.99255610e+00  8.65411949e+00  7.99924850e+00 -1.00000000e+00\n",
      " -1.09725952e-01  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 350: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.51253128 -2.09959674  3.06300354  0.86931217 -0.16978188  0.08896018\n",
      "  0.45558366 -0.51174849 -0.25130853 -0.17774661 -1.14941442  1.8249532\n",
      "  0.72904253 -1.75428009 -6.01807976  3.68877411  0.23226342  0.32290518\n",
      " -0.91402477  0.07965397 -0.43454581  0.09988936 -0.55984288 -4.17779922\n",
      "  1.3420471   2.62879062  7.51261902 -1.          2.74964523  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 360: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.8772583  -2.99378395  1.88552475  0.93295968 -0.2312104   0.06638192\n",
      "  0.26780879  0.54672152 -0.11325286 -0.17669018 -0.74774343 -0.72205406\n",
      " -1.85088205 -4.93473816 -6.93188381  5.13778687  0.06009767 -0.36826482\n",
      " -0.88197756 -0.28789729 -0.27833915  0.36375752 -0.29941088 -1.08049595\n",
      "  0.23078263 -1.62919378  6.03845596 -1.          5.24757385  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 370: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.71120453 -3.10000372  1.87099457  0.94055599 -0.2101716   0.05816164\n",
      "  0.26038343  0.35582554  0.30226603  0.49597898  2.10134149 -1.53965104\n",
      " -0.56923133 -4.1839447  -8.14960194  3.68086243  0.09416103 -0.08994959\n",
      " -0.97185481 -0.19631867  0.96275276 -0.14838187 -0.54002041  1.38077366\n",
      " -2.42523289 -5.14643383  3.77054214 -1.          7.05570984  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 380: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.63095856 -3.46200585 -1.17325974  0.9653762  -0.20462979 -0.03355092\n",
      " -0.15827112  0.30606219 -0.0218653   0.06618612  0.25594816  0.24420387\n",
      " -1.10289705 -1.53764725 -8.25584316 -0.47476578 -0.26468194 -0.33683169\n",
      " -0.89193398  0.14471252  0.51109082  1.13984108  1.06488323  6.68393755\n",
      "  1.13303983 -5.67570829  1.00698471 -1.          7.93637085  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 390: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.72092819 -3.63041115 -1.52257919  0.97656393 -0.08827725 -0.01765618\n",
      " -0.19549507 -0.22471605 -0.24995211  0.59140116  2.53317451 -0.80191731\n",
      "  0.62361062  1.69554901 -6.87711    -2.54114151 -0.50549239 -0.44117686\n",
      " -0.57604414  0.4669193  -6.60443497  1.49476659  1.22569799  5.80699968\n",
      "  5.15493107  0.56453139 -1.8889389  -1.          7.77379608  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 400: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.62736511 -3.78727555 -1.12761307  0.98661798  0.07746054  0.01123014\n",
      " -0.14303423 -0.06949066 -0.01694174  0.05696131  0.23601721 -0.04321896\n",
      "  0.27507767  4.07657242 -6.32728672 -1.82312012  0.20025289  0.18692373\n",
      " -0.63992542  0.71795112  6.64441776  0.79927355  0.31151021  0.44947302\n",
      " -0.19180635 -0.05404262 -4.53656387 -1.          6.58935547  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 410: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-4.32621002e-01 -3.96400428e+00 -3.19702148e-01  9.97746825e-01\n",
      " -5.38430698e-02 -2.16363394e-03 -3.99695747e-02 -4.10606474e-01\n",
      "  1.45897018e-02 -1.64721623e-01 -6.61170483e-01 -7.56968483e-02\n",
      "  1.64141428e+00  1.88476562e+00 -8.01255035e+00  3.75869751e-01\n",
      " -2.57401675e-01 -3.46243292e-01 -7.82888293e-01  4.48269844e-01\n",
      " -8.42611343e-02 -5.57179630e-01 -6.00326478e-01 -2.83303332e+00\n",
      " -2.39332771e+00  5.20048952e+00 -6.58785248e+00 -1.00000000e+00\n",
      "  4.53874969e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 420: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.31765366 -3.45580101  1.9945755   0.96550995 -0.03820612  0.01018324\n",
      "  0.25734624 -0.04195129 -0.02414715 -0.04215455 -0.19469878  0.09680119\n",
      "  0.13830985 -0.07950592 -9.01037598  3.37514496  0.02294152  0.01987873\n",
      " -0.99641049  0.0790237   0.43244261 -0.03256816 -0.64860135 -3.181952\n",
      " -0.27238047 -1.63112998 -7.77317047 -1.          1.89151764  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 430: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.12749481e-01 -3.74291635e+00 -1.40464401e+00  9.83745158e-01\n",
      " -2.60628574e-02 -4.56958264e-03 -1.77610248e-01  1.23448217e+00\n",
      "  3.51808429e-01 -1.01859891e+00 -4.33278751e+00  1.74850357e+00\n",
      " -4.64717674e+00 -3.25697708e+00 -7.37399530e+00 -2.49827194e+00\n",
      " -7.00771660e-02  6.26665726e-02 -7.94897914e-01 -5.99415839e-01\n",
      "  3.20962548e+00  1.59502089e-01  2.75570720e-01 -7.23554993e+00\n",
      "  1.88339019e+00 -1.12664423e+01 -7.93670273e+00 -1.00000000e+00\n",
      " -1.00435638e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 440: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-3.16349792 -1.62686276 -1.85615158  0.82011521 -0.39912331 -0.17939562\n",
      " -0.36868536 -1.39260733 -0.1282112   0.10767019  0.41338044 -2.97477484\n",
      "  1.80437338 -5.70599747 -3.68781567 -6.12431717  0.17305888  0.57784086\n",
      " -0.78029525 -0.1651967   2.28265381 -1.84336996 -3.43699145  3.4894495\n",
      "  5.5071435  -0.7509256  -7.05695724 -1.         -3.76820374  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 450: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.40861511 -2.82732344 -1.50383759  0.92102891 -0.30641708 -0.07581615\n",
      " -0.22818036 -0.90496439 -0.48445988  0.87974459  3.18423963 -3.56029153\n",
      "  1.31493294 -3.8391304  -4.54302311 -5.57671738  0.24749643  0.72787768\n",
      " -0.60880941 -0.19568029  0.99023992  0.47174671  0.91879714  3.02182436\n",
      " -1.32520807  2.51988435 -5.24957657 -1.         -6.03671646  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 460: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-7.84130096e-01 -3.92205858e+00  9.19036865e-02  9.95118916e-01\n",
      " -9.79915261e-02  1.16166030e-03  1.16041498e-02 -5.72755516e-01\n",
      "  3.93108791e-03  3.30216616e-01  1.30043685e+00 -2.40728095e-01\n",
      "  2.25845337e+00 -8.53290558e-01 -6.98389244e+00 -2.79253006e+00\n",
      "  1.30998015e-01  6.92800343e-01 -7.09099889e-01 -6.68460783e-03\n",
      " -3.89830172e-01 -2.58494735e-01  3.30557793e-01  3.45471454e+00\n",
      " -1.88619733e+00  4.19361019e+00 -2.75213623e+00 -1.00000000e+00\n",
      " -7.51170731e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 470: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.32595825 -3.59262466  1.73379898  0.97427422  0.03956733 -0.00898238\n",
      "  0.22168331 -0.58417976  0.14560811  0.31270245  1.38298869  1.08199394\n",
      "  2.07982731  1.55416107 -7.77024317  0.61195374  0.04461695  0.47503883\n",
      " -0.8630808   0.16564736 -0.33657628 -0.14976341  0.50490957  4.06074333\n",
      "  1.39738297  4.58293533  0.10707474 -1.         -7.99928284  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 480: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.58682632 -2.75187922  2.44173813  0.91633064  0.18848665 -0.07118203\n",
      "  0.34604076  0.00787959  0.44819459  0.50812799  2.51720929  0.76131541\n",
      " -0.71055335  4.04750824 -7.48951578  3.74130249 -0.13603579  0.05790408\n",
      " -0.96207041  0.22926408 -2.33021832  0.01358974 -0.51560223  2.37179399\n",
      " -1.90471554  7.82026482  2.95220947 -1.         -7.43535233  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 490: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.24373245 -2.51403427  2.17024231  0.89713401  0.27362981 -0.1012219\n",
      "  0.33171007 -0.94036049 -0.29067725 -0.35223934 -1.5138464   1.18227613\n",
      "  3.06581497  3.05860138 -7.13311386  4.70701599 -0.13111004 -0.13538924\n",
      " -0.96779376 -0.16689885  2.57479978  1.6285702  -1.39466476 -5.74306965\n",
      " -0.17341229 -2.98210454  5.40927505 -1.         -5.89404297  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 500: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.97185516e-01 -3.89288425e+00  9.06341553e-01  9.93232608e-01\n",
      "  2.43815184e-02 -2.70483200e-03  1.13522373e-01  9.74116564e-01\n",
      " -2.03431413e-01 -8.07062268e-01 -3.33961987e+00 -1.16910839e+00\n",
      " -3.73619890e+00 -1.12299347e+00 -8.65951538e+00  3.43852997e+00\n",
      "  1.11819126e-01 -3.75212014e-01 -8.91696692e-01 -2.27133274e-01\n",
      " -9.48347330e-01  6.58168733e-01  2.00563490e-01 -3.51266742e+00\n",
      "  4.84712422e-02 -2.41854501e+00  7.15529251e+00 -1.00000000e+00\n",
      " -3.57796097e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 510: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.88946915e+00 -2.65797448e+00 -8.00674438e-01  9.10969019e-01\n",
      " -3.86230618e-01 -5.65267988e-02 -1.33289337e-01 -3.95461231e-01\n",
      "  1.00350060e-01 -3.25792909e-01 -9.59390819e-01  6.07672393e-01\n",
      "  1.35172319e+00 -4.76644897e+00 -7.38060284e+00 -1.65618896e-01\n",
      " -3.14060450e-01 -2.14339241e-01 -9.24625516e-01 -2.21882965e-02\n",
      "  1.88548231e+00 -9.53644454e-01  3.52457399e-03 -3.54187822e+00\n",
      " -2.65535688e+00 -4.69462681e+00  7.96074295e+00 -1.00000000e+00\n",
      " -7.91568756e-01  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 520: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.77074051e+00 -3.58920169e+00 -8.81958008e-03  9.74104524e-01\n",
      " -2.26095140e-01 -2.69094715e-04 -1.18595315e-03  5.24472117e-01\n",
      " -9.26927140e-04 -1.14541829e-01 -4.13875669e-01  1.86536938e-01\n",
      " -1.89659262e+00 -4.57574081e+00 -7.61481953e+00 -2.25745392e+00\n",
      "  4.33527939e-02  4.24302667e-01 -8.48594248e-01 -3.13010633e-01\n",
      " -2.86634266e-02 -5.05725741e-01  4.63059455e-01  1.85540485e+00\n",
      " -8.12967777e-01 -4.39594507e+00  7.71975708e+00 -1.00000000e+00\n",
      "  2.09888840e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 530: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 0.47658157 -3.09804964 -2.49459076  0.94195724  0.05599832  0.01968592\n",
      " -0.33044413 -0.27869543 -0.83868766  1.03573489  5.33700991 -0.31873462\n",
      "  1.17798638 -0.55390549 -7.95000029 -3.51344299  0.09344883 -0.16883503\n",
      " -0.95493722 -0.22551514 -1.61791062 -1.42296398 -0.39966193  6.10898829\n",
      "  2.16106772  5.37242413  6.46401215 -1.          4.71344757  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 540: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.83864212 -2.64457893 -1.00202179  0.90923822  0.37586799  0.06836531\n",
      " -0.16533419 -0.48085794 -0.12305384  0.31771898  0.97648263  0.3981494\n",
      "  1.63208115  3.73999023 -6.27002859  0.45076752  0.4542276  -0.47637179\n",
      " -0.75261068  0.01801308 -0.56980842  0.43618327  0.46846735  4.25894833\n",
      "  1.66144919  5.05657721  4.35856628 -1.          6.7084198   0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 550: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.9444809  -3.48824334  0.27420425  0.9675709   0.24957514 -0.00971673\n",
      "  0.03774052 -0.80468559  0.01343145  0.21718483  0.76751083  0.59423989\n",
      "  2.80693364  4.02186966 -7.40621376  3.11022949  0.12604409 -0.49378923\n",
      " -0.83706927  0.19899796  1.03406751  0.02662686 -0.28684857  0.91667098\n",
      " -3.31207705  2.97080994  1.68019104 -1.          7.82157135  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 560: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 3.34075928e-01 -3.82111979e+00  1.13816071e+00  9.88788903e-01\n",
      "  4.11572047e-02 -5.96812693e-03  1.43412054e-01 -3.45682114e-01\n",
      "  7.59374071e-03  2.63128188e-02  1.09723531e-01  3.92739177e-01\n",
      "  1.32813859e+00  2.02771378e+00 -8.53905296e+00  3.85897064e+00\n",
      " -7.60204569e-02 -3.67878377e-01 -8.95847201e-01  2.37369627e-01\n",
      "  1.44204807e+00 -7.25687981e-01 -8.64252031e-01 -4.12900591e+00\n",
      " -5.31443214e+00  1.48344606e-01 -1.21904755e+00 -1.00000000e+00\n",
      "  7.90657806e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 570: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.99678421 -3.77561736  0.88574219  0.98564929 -0.12405922  0.01448957\n",
      "  0.11355603  1.38996649 -0.3507477  -1.33308721 -5.40875769 -0.20343801\n",
      " -5.58600855 -3.32659149 -8.94922829  2.5515213   0.0335339  -0.18726452\n",
      " -0.94284618 -0.27358475 -0.75503659  0.67142767 -0.04424619 -8.65145588\n",
      "  0.8131941  -5.51455784 -3.95804214 -1.          6.95225525  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 580: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-3.52479935e+00 -1.49891770e+00 -1.19592667e+00  8.13055336e-01\n",
      " -4.81404990e-01 -1.66819721e-01 -2.81711847e-01  7.69812286e-01\n",
      " -1.26547679e-01  1.65840372e-01  4.00157094e-01  3.09813976e-01\n",
      " -1.62107480e+00 -6.07275772e+00 -5.62879324e+00 -1.96227646e+00\n",
      " -4.30675417e-01 -2.48963535e-02 -9.02157247e-01  3.34819476e-03\n",
      "  3.58831495e-01  1.12746529e-01  1.67733029e-01  1.46961856e+00\n",
      "  4.80218917e-01 -4.43899250e+00 -6.17675400e+00 -1.00000000e+00\n",
      "  5.08406830e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 590: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.85313034 -3.61987233 -1.48323822  0.97573495 -0.10467002 -0.0206188\n",
      " -0.19120792  0.73188287 -0.51138443  1.31040978  5.49321508 -0.22285108\n",
      " -3.15500689 -3.41524506 -6.0462985  -4.87624741 -0.17444067  0.67013896\n",
      " -0.64942515 -0.31421539  2.56959343  1.04915297  1.01411939  5.63526201\n",
      "  5.70729208 -1.79346323 -7.5835228  -1.          2.54758835  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 600: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.47194672 -3.28547144 -1.75262451  0.9534418   0.18080673  0.04498189\n",
      " -0.23713776 -0.14978161 -0.36774197  0.68861413  2.93814898  0.70773906\n",
      "  1.01703703  1.68900681 -4.36387682 -5.57012177 -0.22270389  0.85037577\n",
      " -0.46797282  0.09091476 -0.30958104 -0.72801161  0.44247535  6.89216328\n",
      " -0.50247055  0.14833343 -7.99344635 -1.         -0.32378387  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 610: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.95079803 -2.64356732 -0.60128403  0.91065401  0.39805844  0.0443179\n",
      " -0.10146257 -0.52599913  0.13266453 -0.56111068 -1.55451632 -1.99971151\n",
      "  0.98444647  5.07468033 -5.97075844 -3.734272   -0.30027205  0.49737951\n",
      " -0.79568988  0.17125404 -0.41099003 -1.24246514 -0.38747808  1.49361169\n",
      " -5.05710745  2.27436042 -7.3526268  -1.         -3.15259552  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 620: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 7.27996826e-02 -3.98835778e+00  3.05175781e-01  9.99237359e-01\n",
      "  9.04775504e-03 -3.41037172e-04  3.79833020e-02  2.35869121e-02\n",
      " -6.85466006e-02 -8.92560601e-01 -3.59700918e+00 -1.35058269e-01\n",
      " -8.46827179e-02  3.03330231e+00 -7.53813839e+00  2.71873474e-02\n",
      "  2.14298725e-01  2.79771149e-01 -7.39739716e-01  5.73227167e-01\n",
      "  6.45197690e-01 -1.65354013e+00  9.53551769e-01 -3.94661260e+00\n",
      "  4.40476179e+00  6.32080746e+00 -5.74530792e+00 -1.00000000e+00\n",
      " -5.56699371e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 630: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.58779526 -2.71553755  2.4833374   0.91369504 -0.18809552  0.07261957\n",
      "  0.35285664 -1.40194976 -0.09825969 -0.11453807 -0.55818862  3.55728865\n",
      "  3.78052688 -0.01062393 -5.83853483  3.86843872 -0.65603095 -0.38679379\n",
      " -0.49996755  0.41236684 -3.65305662  1.84819543 -0.95334107 -3.58471251\n",
      " -0.11854388  4.32338715 -3.38276291 -1.         -7.24961472  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 640: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.65270996 -3.18289351  2.34082031  0.94746274 -0.07742129  0.0252819\n",
      "  0.3093237  -0.06723683  0.43321994  0.59457856  2.9109838  -0.26642889\n",
      "  0.52330786  0.76628113 -6.79097176  6.06082153 -0.81405485 -0.27387398\n",
      "  0.20086156 -0.47112885  1.17529774 -1.38622546 -0.08580042  0.92823178\n",
      " -4.11172724  2.91452289 -0.57555771 -1.         -7.97927094  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 650: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 5.51891327e-01 -3.66338825e+00  1.51432037e+00  9.78717148e-01\n",
      "  6.75015748e-02 -1.33346412e-02  1.93335414e-01  8.63211393e-01\n",
      "  1.37055025e-03  3.17540066e-03  1.37733947e-02 -1.35990810e+00\n",
      " -3.15726852e+00  2.28837204e+00 -7.81106043e+00  4.94450378e+00\n",
      " -8.52969289e-01 -2.17861578e-01  7.45734647e-02 -4.68421489e-01\n",
      " -5.73288500e-01  6.49882257e-02  2.45802402e-01  7.67017841e-01\n",
      "  5.08747697e-02 -4.42163086e+00  2.30730820e+00 -1.00000000e+00\n",
      " -7.66004944e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 660: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.60522461e-01 -3.74675798e+00  1.39646149e+00  9.84090090e-01\n",
      "  1.96593925e-02 -3.49616492e-03  1.76544622e-01 -6.15545988e-01\n",
      "  1.60242781e-01  4.48369622e-01  1.91348326e+00  8.85998726e-01\n",
      "  2.31028581e+00  1.68593979e+00 -9.20786953e+00  2.19231033e+00\n",
      " -9.69512343e-01 -2.41144791e-01 -3.64767294e-03  4.33802232e-02\n",
      "  3.10365391e+00  3.23419213e-01 -1.77268696e+00 -3.54761672e+00\n",
      " -2.05261230e+00 -8.68393230e+00  4.88687897e+00 -1.00000000e+00\n",
      " -6.33391190e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 670: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.23004150e+00 -3.78885746e+00 -3.78738403e-01  9.86724436e-01\n",
      "  1.54659033e-01  7.70096527e-03 -4.89507988e-02  5.52255511e-01\n",
      "  4.46375087e-02 -5.05204976e-01 -1.93482089e+00 -4.55710381e-01\n",
      " -2.15527844e+00  5.78231812e-02 -8.15588570e+00 -2.18025589e+00\n",
      " -8.17310035e-01  2.79070348e-01  2.93450892e-01  4.09890950e-01\n",
      " -8.87868643e-01 -6.65476561e-01 -4.30656970e-01 -2.84793162e+00\n",
      " -1.45551205e+00 -3.83804083e+00  6.82406616e+00 -1.00000000e+00\n",
      " -4.17518234e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 680: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.7217865  -2.84546471 -2.23303223  0.92265898 -0.20759164 -0.07132019\n",
      " -0.3170481   0.41776821  0.18832061 -0.2457144  -1.12791646  1.34352076\n",
      " -0.88800246 -3.14750671 -7.87852478 -3.11246872 -0.97558594  0.04628291\n",
      "  0.17375766 -0.12608814 -1.81025267  0.76125789 -0.40324983 -2.94967937\n",
      "  4.25082731  6.44494772  7.86422729 -1.         -1.46763611  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 690: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.23275375e+00 -3.32372570e+00  1.34590149e-01  9.56794024e-01\n",
      " -2.90086120e-01  5.60174836e-03  1.90739967e-02 -1.97943795e+00\n",
      "  6.71595393e-04 -8.70873868e-01 -2.94697213e+00  1.89164710e+00\n",
      "  6.69972849e+00 -5.38282776e+00 -8.40414143e+00  6.43783569e-01\n",
      " -9.64180827e-01  2.56264865e-01  1.32996775e-02 -6.71328083e-02\n",
      "  2.09100699e+00 -2.13829851e+00  1.16912353e+00 -2.60622048e+00\n",
      " -1.14411449e+00 -9.76546407e-01  7.87063980e+00 -1.00000000e+00\n",
      "  1.43283844e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 700: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.1765976  -3.23345327  0.9166832   0.9503268  -0.27952668  0.03864861\n",
      "  0.13133964  0.65730953 -0.06919844 -0.23344815 -0.82549834 -0.12882008\n",
      " -2.28613424 -4.29983902 -8.51182842  0.80015182 -0.97763717  0.10210199\n",
      " -0.13744877  0.12210126 -0.95378816  0.11961502  1.40358663  4.28110409\n",
      " -2.63798547  0.10230495  6.84245682 -1.          4.14497375  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 710: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-3.46229553e-01 -3.97598100e+00  2.89623260e-01  9.98417675e-01\n",
      " -4.30710800e-02  1.47286255e-03  3.61230262e-02  8.23590636e-01\n",
      "  9.09107849e-02  1.01845980e+00  4.08834267e+00 -7.28779256e-01\n",
      " -3.24103856e+00 -1.18580627e+00 -9.43163395e+00 -1.09093475e+00\n",
      " -9.55081820e-01  1.00590892e-01  2.69732252e-03  2.78734744e-01\n",
      "  1.15937382e-01  1.13629413e+00 -5.09079874e-01  2.55524826e+00\n",
      " -6.03594005e-01 -5.20979595e+00  4.91483307e+00 -1.00000000e+00\n",
      "  6.31224060e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 720: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.70924759 -3.46816874 -1.03530121  0.96585059  0.21556023  0.03131137\n",
      " -0.14030738 -0.18073568  0.04183682 -0.13924605 -0.52825946 -0.42852533\n",
      "  0.55690759  1.87352371 -7.2085886  -4.35514832 -0.78533429  0.04528198\n",
      "  0.26930845  0.55558306  1.6991334  -0.76204693  0.44712251  2.69853163\n",
      "  4.76133871 -3.39758444  2.34115219 -1.          7.64977264  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 730: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-0.51552963 -3.77233362 -1.2335968   0.9856208  -0.06343652 -0.01011539\n",
      " -0.15628542 -0.53550321  0.33778983 -1.00203919 -4.2275033  -0.25123248\n",
      "  2.17454386  1.00609589 -8.28777885 -3.74418259 -0.86879992 -0.29871503\n",
      " -0.16149996  0.36038005  0.83288866 -0.98022664  0.09991129 -4.80047083\n",
      "  1.81598854  4.40095711 -0.54027557 -1.          7.98173523  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 740: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.25384903e+00 -3.30717230e+00  1.26552582e-01  9.55885112e-01\n",
      " -2.93121457e-01  5.63284149e-03  1.82167850e-02  5.46502352e-01\n",
      " -3.99979539e-02 -8.10117185e-01 -2.72935796e+00  1.69212401e+00\n",
      " -1.92476106e+00 -1.60535431e+00 -7.36145020e+00 -8.39920044e-01\n",
      " -6.71673477e-01 -2.13293180e-01 -5.56959689e-01  4.39495891e-01\n",
      " -2.00765610e+00 -7.59120047e-01 -9.24228489e-01 -5.49581051e+00\n",
      " -3.70480371e+00  3.69451571e+00 -3.35068130e+00 -1.00000000e+00\n",
      "  7.26449585e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 750: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.11202621e+00 -3.70114636e+00  1.04132462e+00  9.80998158e-01\n",
      " -1.38385266e-01  1.89564954e-02  1.34657875e-01  1.02928817e+00\n",
      "  1.14401832e-01  3.77977848e-01  1.52268195e+00 -1.58080029e+00\n",
      " -3.66802478e+00 -4.29493332e+00 -8.16189480e+00  9.97436523e-01\n",
      " -8.82961214e-01  4.44140881e-01 -5.85702481e-03  1.51934683e-01\n",
      " -1.40288997e+00  1.63362527e+00 -2.13194084e+00 -5.18596601e+00\n",
      "  2.39127970e+00  2.70467257e+00 -5.72063828e+00 -1.00000000e+00\n",
      "  5.59233856e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 760: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.49425888 -3.09839606 -0.46619797  0.94193172 -0.32751903 -0.02434921\n",
      " -0.07002196 -0.0149542   0.09412332 -0.62719274 -2.01971745  1.53183997\n",
      "  0.27804071 -6.53266525 -7.3499403  -0.05416107 -0.90277559  0.41018346\n",
      "  0.07302263 -0.10683405  1.39677155 -0.2627354   1.37692809 -0.08640365\n",
      " -3.58035755 -4.19814587 -7.3386116  -1.          3.18508148  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 770: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-2.07798767e+00 -3.41973567e+00  1.26152039e-01  9.63183045e-01\n",
      " -2.68225014e-01  4.85460367e-03  1.76131986e-02  7.42405236e-01\n",
      "  3.28840762e-02  6.37708187e-01  2.18054032e+00 -1.48419523e+00\n",
      " -2.46200109e+00 -3.47625351e+00 -8.10104275e+00 -1.90470123e+00\n",
      " -9.00172651e-01  5.81215844e-02 -2.04469472e-01  3.80136013e-01\n",
      " -1.48906574e-01 -5.01363873e-01  1.37358856e+00  9.69925308e+00\n",
      " -2.91290855e+00 -3.77756190e+00 -7.99193573e+00 -1.00000000e+00\n",
      "  3.59138489e-01  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 780: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 2.15454865 -3.15331173 -1.21269226  0.94439656  0.27432725  0.0503845\n",
      " -0.17412956  1.1772331  -0.51872009  1.46413219  5.37683058  4.36187124\n",
      " -2.77788639  2.80840683 -6.91925335 -4.59583282 -0.80959684  0.01861215\n",
      "  0.27844566  0.5164054  -0.38993225  1.11417019  0.6199581   6.49162483\n",
      "  5.3180275  -2.5428164  -7.59471512 -1.         -2.51401901  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 790: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 3.3103981  -0.93290669 -2.07238388  0.74534082  0.39160275  0.25095025\n",
      " -0.47763836  0.74047792 -0.01660888  0.00793608  0.04200481  1.55090618\n",
      " -0.67348486  5.12334442 -4.44136477 -4.48278809 -0.8801055   0.16506463\n",
      " -0.43764439  0.08145827 -0.91340423 -0.40638348  0.02538596  0.72683316\n",
      "  1.4497987   2.19293618 -6.19916916 -1.         -5.05670929  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 800: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 1.93190765 -2.49302411 -2.47580338  0.89639682  0.22952677  0.09401775\n",
      " -0.36735684 -1.81090605  0.17771463 -0.1677639  -0.86004078 -4.96137476\n",
      "  4.02794695  6.25986099 -5.02534962 -3.80560303 -0.75511003 -0.62327993\n",
      " -0.19742417  0.04852645  0.60938698  0.82938528  2.15907025  1.68394327\n",
      " -0.06145325  2.83039212 -3.98874283 -1.         -6.93469238  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 810: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-4.07371521e-02 -3.98446369e+00  3.67816925e-01  9.98938739e-01\n",
      " -5.06142247e-03  1.53484812e-04  4.57797125e-02 -6.45263851e-01\n",
      " -9.54984650e-02 -1.21056283e+00 -4.88300800e+00  1.34738967e-01\n",
      "  2.59215069e+00  2.74098587e+00 -6.16542387e+00 -1.91917419e-02\n",
      " -2.63341188e-01 -1.73782751e-01 -5.44266045e-01  7.77319372e-01\n",
      "  3.15863585e+00  4.98321831e-01 -5.58807492e-01 -8.37012959e+00\n",
      "  1.11109304e+00  6.18096161e+00 -1.25399399e+00 -1.00000000e+00\n",
      " -7.90110779e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n",
      "Step 820: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [-1.85629272 -3.23014021  1.46683502  0.94959885 -0.23237342  0.05001123\n",
      "  0.20436151  0.26698014 -0.03836498 -0.08376025 -0.3288089  -0.2418263\n",
      " -0.93729162 -0.68641663 -6.97385216  1.69894409 -0.66904747 -0.29214555\n",
      " -0.52138907  0.44179165 -2.45888186  0.66238004 -0.61527568 -2.5846529\n",
      " -6.0295496   0.36137947  1.64559555 -1.         -7.82892227  0.\n",
      "  1.          0.         -0.52221441]\n",
      "Step 830: max hand movement from start: 0.0000\n",
      "Full obs (agent 0): [ 3.07510376e-01 -3.85984111e+00 -1.01431274e+00  9.91112947e-01\n",
      "  3.79527062e-02  4.79878113e-03 -1.27403602e-01  5.93591928e-01\n",
      " -3.64974052e-01  1.45947051e+00  6.04449368e+00  8.53014708e-01\n",
      " -2.24508405e+00 -2.79727936e-01 -9.07250690e+00 -3.31001282e-02\n",
      " -9.38187599e-01  1.20608628e-01 -7.19652772e-02 -3.16352159e-01\n",
      " -1.63615549e+00 -2.76753879e+00 -1.75771809e+00 -2.68738461e+00\n",
      "  7.28870964e+00 -7.26442575e-01  4.32886505e+00 -1.00000000e+00\n",
      " -6.72762299e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(num_agents, action_size)  \u001b[38;5;66;03m# select random actions\u001b[39;00m\n\u001b[1;32m     11\u001b[0m actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)                    \u001b[38;5;66;03m# clip to [-1, 1]\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m env_info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m[brain_name]            \u001b[38;5;66;03m# step the environment\u001b[39;00m\n\u001b[1;32m     14\u001b[0m next_states \u001b[38;5;241m=\u001b[39m env_info\u001b[38;5;241m.\u001b[39mvector_observations\n\u001b[1;32m     15\u001b[0m rewards \u001b[38;5;241m=\u001b[39m env_info\u001b[38;5;241m.\u001b[39mrewards\n",
      "File \u001b[0;32m~/anaconda3/envs/unity_env/lib/python3.10/site-packages/unityagents/environment.py:368\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_brains[b]\u001b[38;5;241m.\u001b[39mvector_action_space_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscrete\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vector_action[b]) \u001b[38;5;241m==\u001b[39m n_agent) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    358\u001b[0m                 (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_brains[b]\u001b[38;5;241m.\u001b[39mvector_action_space_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    359\u001b[0m                     vector_action[b]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_brains[b]\u001b[38;5;241m.\u001b[39mvector_action_space_size \u001b[38;5;241m*\u001b[39m n_agent)):\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnityActionException(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a mismatch between the provided action and environment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms expectation: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe brain \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m action(s), but was provided: \u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_brains[b]\u001b[38;5;241m.\u001b[39mvector_action_space_type,\n\u001b[1;32m    366\u001b[0m             \u001b[38;5;28mstr\u001b[39m(vector_action[b])))\n\u001b[0;32m--> 368\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexchange\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_step_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unity_env/lib/python3.10/site-packages/unityagents/rpc_communicator.py:78\u001b[0m, in \u001b[0;36mRpcCommunicator.exchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m message\u001b[38;5;241m.\u001b[39munity_input\u001b[38;5;241m.\u001b[39mCopyFrom(inputs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munity_to_external\u001b[38;5;241m.\u001b[39mparent_conn\u001b[38;5;241m.\u001b[39msend(message)\n\u001b[0;32m---> 78\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munity_to_external\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unity_env/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/anaconda3/envs/unity_env/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/unity_env/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                 # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                         # initialize the score (for each agent)\n",
    "\n",
    "initial_hand_pos = states[:, 29:32].copy()            # save initial hand positions\n",
    "max_delta = 0.0                                        # track the max movement across any agent\n",
    "\n",
    "step_count = 0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size)  # select random actions\n",
    "    actions = np.clip(actions, -1, 1)                    # clip to [-1, 1]\n",
    "    \n",
    "    env_info = env.step(actions)[brain_name]            # step the environment\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    \n",
    "    hand_pos = states[:, 29:32]\n",
    "    step_delta = np.linalg.norm(hand_pos - initial_hand_pos, axis=1)\n",
    "    max_delta = max(max_delta, np.max(step_delta))\n",
    "    \n",
    "    step_count += 1\n",
    "    if step_count % 10 == 0:\n",
    "        print(f\"Step {step_count}: max hand movement from start: {np.max(step_delta):.4f}\")\n",
    "        print(\"Full obs (agent 0):\", states[0])\n",
    "\n",
    "    if np.any(dones):\n",
    "        break\n",
    "\n",
    "print(f\"\\nTotal score (averaged over agents): {np.mean(scores):.2f}\")\n",
    "print(f\"Max hand movement during episode: {max_delta:.4f}\")\n",
    "\n",
    "if max_delta < 1e-3:\n",
    "    print(\"⚠️  WARNING: Hand position did not change. Unity environment may be ignoring actions.\")\n",
    "else:\n",
    "    print(\"✅ Hand movement detected. Unity responds to actions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Architecture Decisions for TD3 Training with Unity ML-Agents**\n",
    "\n",
    "## **1️⃣ Use Replay Buffer in Its Own Process**\n",
    "### ✅ Justification:\n",
    "- **Avoids race conditions** when both the training and data collection processes interact with the buffer.\n",
    "- **Prevents memory contention** by isolating replay storage operations from CPU/GPU workloads.\n",
    "- **Decouples storage from compute-intensive tasks**, making data access smoother.\n",
    "\n",
    "---\n",
    "\n",
    "## **2️⃣ Replay Buffer as the Bridge Between Training and Data Collection**\n",
    "### ✅ Justification:\n",
    "- **Producer-Consumer Model**: The **data collection process (Unity environment)** produces experience data, while the **training process** consumes it for learning.\n",
    "- **Ensures non-blocking behavior**: Training can proceed independently while new data is collected.\n",
    "- **Avoids excessive synchronization overhead**, allowing each process to run at its own pace.\n",
    "\n",
    "---\n",
    "\n",
    "## **3️⃣ Three Separate Processes for Efficiency**\n",
    "### ✅ Justification:\n",
    "1. **Replay Buffer Process**:\n",
    "   - Manages stored experience and handles sampling/insertion requests efficiently.\n",
    "   - Runs in a **dedicated process** to prevent contention with the training loop.\n",
    "\n",
    "2. **Training Process**:\n",
    "   - Fetches batches from the replay buffer asynchronously and updates the TD3 neural networks.\n",
    "   - Utilizes the **GPU fully without waiting** for new experience data.\n",
    "\n",
    "3. **Data Collection Process (Unity Environment)**:\n",
    "   - Steps the environment in parallel for **20 agents**, collecting `(state, action, reward, next_state, done)` tuples.\n",
    "   - Pushes data to the replay buffer **without blocking training**.\n",
    "   - Offloads simulation work to the **CPU**, allowing for efficient resource utilization.\n",
    "\n",
    "---\n",
    "\n",
    "## **🌟 Summary**\n",
    "- **Replay Buffer runs independently** to mediate between training and data collection.\n",
    "- **Training and data collection processes operate in parallel**, preventing bottlenecks.\n",
    "- **Each process is optimized for its specific task**, ensuring full utilization of CPU & GPU resources.\n",
    "\n",
    "This architecture balances **parallelism, efficiency, and stability**, leading to **faster training times** while keeping the system modular and scalable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also decided to use the ReplayBuffer implementation from https://github.com/ShangtongZhang/DeepRL/. His code is superior modularized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of my decisions to utilize a producer-consumer model for the ReplayBuffer I have to place all the code in python files that are directly executed in a terminal. A jupyter notebook is not suitable for parallel / async code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unity_env",
   "language": "python",
   "name": "unity_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
